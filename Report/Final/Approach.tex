%!TEX root = Main.tex
% Design Approach: words
\chapter{Design Theory and Approach} % (fold)
\label{cha:design_approach}

% TODO: What does this chapter give the reader??
%   All the main theory behind the approach
%   A description of what will be done

%TODO: restructure this.  Make hmm_model a subsection of hmm_tasks? and others?
% High level system overview - what exactly was built, where each of the pieces fit, what I needed to learn to build each section.
% Analyse my solution - what does it do, where does it fall short

This chapter provides details of the relevant theory behind HMM based speech recognition systems, as well as a description of the development environments used during the project.

\section{The HMM based model} % (fold)
\label{sec:the_hmm_based_model}
	Due to the flexibility of HMMs, and the complexity of speech, there have been several different approaches to building speech models (the sheer size of the HTK book indicates how much flexibility exists).  However, at this stage the author is more interested in the implementation of the algorithms, rather than devising the best way of modelling speech.  Therefore, it was decided to use the pre-designed models from Voxforge for this project, and build the hardware to work with these models.  Thus, various parameters were fixed from the start, including:

	\begin{itemize}
		\item Sampling rate of audio: 8kHz. %(Low Pass Filter with $\omega_0 = 4kHz$ required).
		\item Window size: 25ms (duration of observation frames).
		\item Frame period: 10ms (time between observation frames).
		\item Pre-processing output: 12 MFCCs, 12 MFCC derivatives, 1 Energy measure.
		\item Output probabilities of HMM states: Single Gaussian distribution, 25-element mean and variance vectors.
		\item Number of monophones: 51 (Includes a monophone for silence.  This is also the number of transition matrices).
		\item Number of senones: ~7000.
		\item Number of HMMs: ~8300\footnote{There are more HMMs than senones because some senones are used in more than one HMM} (each with 3 outputting states).
	\end{itemize}

	The only modification made to the Voxforge models was that they were adapted for the author's voice, primarily to gain confidence with using the HTK and HMMs.  Please see Appendix !!TODO!! for the scripts and HTK configuration files used to generate these models.

	The term `outputting states' refers to states that produce an observation -- most of the HMMs have 5 states in total, but the first and last are non-emitting.  The transition probability from the fourth to last state is the probability of exiting that particular HMM, which is useful for decoding purposes. The senones are context dependent, that is, there are many different senones for each monophone, each with different predecessor and successor monophones.  The number of transition matrices is equal to the number of monophones because...
	% TODO: tidy up the description of my models.  Maybe this needs a whole section??

	\subsection{The HMM tasks} % (fold)
	\label{sub:the_hmm_tasks}
		For an HMM model, denoted as $\lambda$, there are usually three important problems: 
		\begin{itemize}
			\item Design and train the model to accurately represent real data
			\item Finding the probability that an HMM produced a given observation sequence, $P(\lambda | O)$.
			\item Finding the `best' path through a trellis of HMMs to produce a given observation sequence !!TODOequation!!
		\end{itemize}
		For this project, the first problem is solved by using Voxforge (\ref{sec:the_htk}).  The second problem is potentially very computationally expensive, as the speech model may be complex or large.  In particular, this step requires scoring the senones of each HMM for every new observation frame, which is particularly time consuming if the HMMs have continuous output distributions. !!TODO: Speech silicon has refs to confirm this is most expensive!!  This is the step that the project focusses on.

		In all literature encountered, the Viterbi algorithm is the preferred method for solving problem 3.  It is an iterative approach to solving the optimisation problem, and has the added bonus that not much data needs to be stored during the calculation \cite{schuster2006speech}.  This problem is beyond the scope of the current project, but a full explanation of the Viterbi decoding process is available from \cite{rabiner1989tutorial},\cite{melnikoff2003speech},\cite{saeed2008advanced}.
	% subsection the_hmm_tasks (end)

	\subsection{Senone scoring} % (fold)
	\label{sub:senone_scoring}
		As described in previous sections, the FPGA is intended to be used for scoring every senone in the model, for every observation vector.  In this system the new vectors arrive once every 10ms, and there are about 7000 senones that must be evaluated.  The mathematical operations required to do this are now outlined. % !!TODO!! some kind of 'this is x calculations'?

		Each senone $j$ has an $N$-element vector of means, $\mu_j$, and a $N\times N$ matrix of covariances, $\sigma_j$.  However, since MFCCs are uncorrelated, the covariance matrix is diagonal, and $\sigma_j$ is taken as an $N$-element vector.  If the observation vector at time $t$ is denoted as $\mathbf{O}_t = {O_{t1}, O_{t2}, ..., O_{tN}}$, then the score of senone $j$ is given in Equation~\ref{eq:score1}.  However, the hardware complexity may be greatly reduced by taking the logarithms of both sides, removing the requirement to evaluate $N$ exponentials for each senone.  In addition, several parts of the equation may be precomputed, thus reducing the necessary sequence of operations to subtract, square, multiply, and accumulate.  This derivation is shown in Equations \ref{eq:score_ln}--\ref{eq:score_final}, with the final result being the one most suited to hardware implementation.

		\meq{score1}{
			b_j(O_t) = N(O_t; \mu_j,\sigma_j) = product...
		}
		\meq{score_ln}{
			ln of both
		}
		\meq{score_final}{
			final
		}
	% subsection senone_scoring (end)
% section the_hmm_based_model (end)


\section{Hardware environment} % (fold)
\label{sec:hardware_dev_env}
	% Detail the compilation environment etc, which SD card does what...
	As the Micro Arcana is still under active development, part of the project involved setting up and testing the two boards that the project used.

	\subsection{L'Imperatrice} % (fold)
	\label{sub:l_imperatrice_env}
		The ARM-based L'Imperatrice board is still under active development, and several important features on it are very untested.  It is based on a Freescale iMX23 ARMv5 applications processor.  To be used for the project, the following items were required (in order of importance):
		\begin{itemize}
			\item Native or cross compiler set-up
			\item Application UART functionality
			\item GPIO functionality
		\end{itemize}

		An Linux Target Image Builder (LTIB) \nomenclature{LTIB}{Linux Target Image Builder} environment, which is primarily used for setting up board support packages (BSP), was installed on an Ubuntu virtual machine.  It has been used to build and test various kernel configurations, and also includes full cross-compiler support for the board.  It essentially provides a platform on which software for L'Imperatrice may be developed and deployed.
		In addition to LTIB, the ArchLinux build system (ABS) was investigated as a potential alternative to LTIB.  The primary advantage of the ABS is that only a small number of files need to be distributed, which, when run, will download and compile all dependencies of the build.  An ABS configuration exists for the Olinuxino, a Linux board also based on the Freescale iMX23, which may be tweaked to suit the L'Imperatrice.  However, due to lack of time and the relative ease of the LTIB set-up, this was not done.
	% subsection l_imperatrice_env (end)

	\subsection{La Papessa} % (fold)
	\label{sub:la_papessa_env}
		The Xilinx FPGA-based La Papessa board is also actively being developed, and some of its features have not been tested.  In order to facilitate the development of code on the La Papessa board, several combinations of software environments were explored.  The FPGA is a Xilinx Spartan XC3S50AN, which is compatible with the Xilinx ISE Webpack design software package.  However, one drawback to the ISE Webpack is its lack of support for synthesis in SystemVerilog. Besides being syntactically more powerful, SystemVerilog is the HDL that is currently taught to all new undergraduates at the University of Southampton. Having some documentation of a proven way to use SystemVerilog with this board would improve its reception and usage. In addition, SystemVerilog has advantages over Verilog for verification and simulation, which will be used to improve the design.

		Synplify Pro/Premier is an alternative HDL synthesis tool, which is compatible with the Xilinx software toolchain and also supports SystemVerilog. For this reason, and because the author is more familiar with the Synplify design flow, it was decided that Synplify Premier would be used for synthesis during the project.  The other design tasks (port mapping, programming file generation) are accomplished with ISE Webpack (See Appendix !!! for detailed description of this process).
	% subsection la_papessa_env (end)

% section hardware_dev_env (end)


% chapter design_approach (end)